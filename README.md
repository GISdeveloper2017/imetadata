# imetadata
时空数据入库管理引擎

# 运行与设置
## 系统运行命令
在iMetaData子目录下, 运行命令行
```
python.exe ScheduleCreator.py
python.exe ScheduleCreator.py -log /your_log_file_path
```

## 设置
### 全局设置
在根目录下, 修改配置文件settings.py
1. 示例
```python
from imetadata.base.c_settings import CSettings
application = CSettings(
    {
        'databases': [
            {'id': '0', 'type': 'postgresql',
             'host': '127.0.0.1', 'port': '5432', 'database': 'test', 'username': 'postgres', 'password': 'postgres'}
        ],
        'directory': {
            'work': ''
        },
        'metadata': {
            'directory': {
                'view': ''
            },
            'plugins': {
                'dir': [
                    {'plugin': ['plugins_1000_dom_10', 'plugins_1000_dom_12'], 'keyword': 'dom'},
                    {'plugin': ['plugins_1010_dem_10', 'plugins_1010_dem_12'], 'keyword': 'dem'}
                ]
            }
        }
    }
)
```
1. databases
    * 数据库配置节点
    * 配置内容为数组, 可支持多个数据库同时连接
    * 每一个数据库的配置说明:
        * id: 数据库的标识, 配置后, 在代码中可以使用CFactory().give_me_db('[id]')来直接访问该数据库
        * type: 数据库类型, 目前支持postgresql和mysql
        * host: 数据库ip地址
        * port: 数据库访问端口号
        * database: 数据库名称
        * username: 用户名
        * password: 密码(暂时存储明文, 后期改为密文)
1. directory:
    * 目录配置
    * work: 工作路径, 为系统内置进行数据处理的临时目录, 建议大于20G
1. metadata:
    * 数据入库管理模块的专用配置
    * directory:
        * 数管的目录设置
        * view: 数管中用于存储空间数据快视图, 拇指图等文件的根目录, 存储空间自行根据每一个空间数据的元数据存储大小统计
    * plugins:
        * 自定义识别插件的配置
        * dir:
            * 目录识别插件的特定配置
            * 使用数组记录, 支持多个匹配模式
            * 每一个匹配模式的说明:
                * keyword: 
                    * 关键字, 目录必须等于关键词, 则目录下的文件, 按plugin中的设置顺序识别
                    * 注意: 如果关键字为空, 则所有子目录都优先按plugin中的插件顺序识别
                * plugin:
                    * 匹配关键字的目录下, 将按插件顺序识别
                    * 使用数组记录, 支持多个插件
                    * 识别顺序为从左到右
        * 自定义识别插件后, 仍然无法识别的数据, 系统将按内置的插件识别
        
# 业务场景设计
## 系统部署
1. 在数管维护功能\存储维护中
    1. 注册核心存储, 输入存储的网络路径\映射路径\用户名和密码\最大存储量\警告存储量\高级入库配置等内容
    1. 注册入库存储, 输入存储的网络路径\映射路径\用户名和密码等内容
1. 如果核心存储中已经有用户的待入库数据
    1. 在数管维护功能\首次使用
        1. 选择核心存储, 启用首次数据盘点功能
            1. 等待系统自动扫描所有数据
        1. 查看盘点结果
            1. 目录视图
                1. 目录
                1. 子目录
                1. 文件
                1. 被识别出的对象名称及类型
            1. 数据视图
                1. 数据分类
                1. 数据类型
                1. 数据
                    1. 名称
                    1. 类型
                    1. 对应的文件或目录名称
                    1. 空间信息
                        1. 坐标
                        1. 投影
                        1. 分度
                        1. 分带
                    1. 位置信息
                        1. 地理位置
                    1. 可视信息
                        1. 快视图
                        1. 拇指图
                    1. 质检信息
                        1. 质检概要
                        1. 质检详情
                    1. 数据重复情况
                        1. 已入库数据已经有副本
                        1. 本批入库数据中已经有副本
        1. 导出首次盘点报告
            1. 导出盘点报告word

## 数据入库
### 集中式数据入库
#### 简述: 
1. 集中式数据入库, 一般将存储分为核心存储和入库存储
1. 集中式数据入库是指用户在入库存储中, 暂存待入库数据, 由数管系统对待入库数据进行扫描\识别\质检后, 将数据迁移至数管核心存储中
1. 集中式数据管理的最大特点是存储权限清晰, 数据管理系统管理核心存储, 人管理入库存储, 优点是数据安全性高, 缺点是数据使用必须申请
1. 为了提高入库效率, 入库存储与核心存储一般同属于一个物理存储介质, 但入库存储通过网络磁盘共享或者FTP共享模式, 可由入库人员直接访问, 将待入库
    数据拷贝或上传到该存储下
#### 适用数据
1. 卫星数据
1. 单景正射数据
#### 适用场景
1. 对数据安全有较高要求
#### 集中式入库的数据处理流程
##### 数据质检(入库人员角色/数据库管理员角色)
1. 入库人员, 在待入库存储(共享目录)下建立一个文件夹, 将待入库数据复制或上传到该文件夹下
1. 入库人员, 在数管系统\数据入库模块中点击申请入库功能
    1. 显示申请入库界面
    1. 选择待入库数据目录
    1. 系统将显示入库数据子目录及其文件
        1. 用户可以打开每一级子目录, 查看文件
        1. 用户可以针对每一个子目录, 选择该目录下的数据类型
            1. DOM
            1. DEM
            1. 三调
            1. 地理国情
            1. ...
            1. 项目成果数据
            1. 优选卫星数据
            1. 零散卫星数据
            1. 零散成果数据
        1. 根据上述选择的类型, 系统会显示出可选的其他参数项
        1. 入库人员输入参数项
        1. 入库人员可以增加自定义参数项, 并输入对应的内容
    1. 入库人员点击开始扫描质检功能
1. 入库人员可以在界面上看到申请入库的内容
    1. 目录视图(同首次使用盘点结果样式)
    1. 数据视图(同首次使用盘点结果样式)
    1. 可以导出待入库数据清单
1. 入库人员人工浏览数据内容, 判定是否入库
1. 入库人员选择提交入库功能
1. 根据系统配置, 项目可以选择两个分支
    1. 入库人员选择提交入库后, 系统将把待入库数据进行入库处理
        1. 系统将检查校对数据清单与实体数据的一致性, 之后将待入库数据, 从入库存储迁移至核心存储中
        1. 迁移之后, 数据编目也同时移至核心存储
    1. 入库人员选择提交入库后, 系统将等待数据管理员审批后, 方可入库(参见下一步)

##### 数据入库审批(数据管理员角色)
1. 数据管理员通过入库审批功能, 可以查看到申请入库的申请单列表
1. 数据管理员可以打开每一个申请单, 查看申请入库的数据信息
    1. 数据信息的内容同样有目录视图和数据视图(同上, 不再赘述)
    1. 可以导出申请入库数据清单
1. 数据管理员对申请单的信息进行人工判定, 确认是否同意入库
1. 数据管理员对同意入库的数据, 点击同意入库
1. 系统将检查校对数据清单与实体数据的一致性, 并最终将待入库数据, 从入库存储迁移至核心存储中
1. 迁移之后, 数据编目也同时移至核心存储

### 离散式入库的数据处理流程
#### 简述: 
1. 离散式数据入库, 一般只有核心存储
1. 离散式数据入库是指用户直接将待入库数据放置到核心存储中, 由数管系统对待入库数据进行扫描\识别\质检后, 将数据的元数据入库
1. 离散式数据管理的最大特点是兼顾数据入库管理和使用, 系统将核心存储中的数据登记到数管系统数据库, 提供便利的条件进行查询, 同时, 人也可以随时访问核心
    存储中的数据, 不受数管系统的干扰. 优点是数据使用方便, 与传统的共享方式兼容, 缺点是数据安全性低, 极有可能因为人为的误操作, 导致数据丢失, 或者
    元数据与实体状态信息不统一
1. 离散式数据入库与集中式入库的最大区别就是数据由用户放置在指定区域, 入库后, 数据的位置不变
1. 考虑到核心存储将由系统和人共同管理, 建议数据管理员通过FTP模式管理核心存储
#### 适用数据
1. 成果数据
1. 生产支撑的参考数据, 如: 高程数据\基础地理数据等
#### 适用场景
1. 对数据应用有较高要求
#### 离散式入库的数据处理流程
##### 数据质检(入库人员角色/数据库管理员角色)
1. 入库人员, 在待核心存储建立一个文件夹, 将待入库数据复制或上传到该文件夹下
1. 入库人员, 在数管系统\数据入库模块中点击申请入库功能
    1. 显示申请入库界面
    1. 选择待入库数据目录
    1. 系统将显示入库数据子目录及其文件
        1. 用户可以打开每一级子目录, 查看文件
        1. 用户可以针对每一个子目录, 选择该目录下的数据类型
            1. DOM
            1. DEM
            1. 三调
            1. 地理国情
            1. ...
            1. 项目成果数据
            1. 优选卫星数据
            1. 零散卫星数据
            1. 零散成果数据
        1. 根据上述选择的类型, 系统会显示出可选的其他参数项
        1. 入库人员输入参数项
        1. 入库人员可以增加自定义参数项, 并输入对应的内容
    1. 入库人员点击开始扫描质检功能
1. 入库人员可以在界面上看到申请入库的内容
    1. 目录视图(同首次使用盘点结果样式)
    1. 数据视图(同首次使用盘点结果样式)
    1. 可以导出待入库数据清单
1. 入库人员人工浏览数据内容, 判定是否入库
1. 入库人员选择提交入库功能
1. 根据系统配置, 项目可以选择两个分支
    1. 入库人员选择提交入库后, 系统将把待入库数据进行入库处理
        1. 数管系统将把待入库的数据编目更新为已入库编目
    1. 入库人员选择提交入库后, 系统将等待数据管理员审批后, 方可入库(参见下一步)

##### 数据入库审批(数据管理员角色)
1. 数据管理员通过入库审批功能, 可以查看到申请入库的申请单列表
1. 数据管理员可以打开每一个申请单, 查看申请入库的数据信息
    1. 数据信息的内容同样有目录视图和数据视图(同上, 不再赘述)
    1. 可以导出申请入库数据清单
1. 数据管理员对申请单的信息进行人工判定, 确认是否同意入库
1. 数据管理员对同意入库的数据, 点击同意入库
1. 系统将检查校对数据清单与实体数据的一致性
1. 系统将把待入库的数据编目更新为已入库编目

## 数据盘点
1. 数据管理员通过数据盘点功能, 可以查看核心存储
1. 数据管理员可以对指定核心存储, 使用定期盘点功能
1. 系统将在后台进行数据盘点
    1. 数据盘点仅仅检查数据和实体数据的一致性, 主要检查如下内容:
        1. 每一个数据的附属文件是否都存在, 文件大小\最后修改日期是否和元数据库中的内容一致
        1. 每一个数据的主文件是否存在, 文件大小\最后修改日期是否和元数据库中的内容一致
    1. 数据盘点后, 将对不一致的数据进行记录
1. 数据管理员可以查看盘点结果
    1. 数据视图
        1. 数据分类
        1. 数据类型
        1. 数据
            1. 名称
            1. 类型
            1. 元数据中记录的大小
            1. 元数据中记录的最后修改日期
            1. 实体是否存在
            1. 实体大小
            1. 实体最后修改日期
    1. 可以导出盘点报告
1. 数据管理员可以将有问题的元数据, 批量标记为不可用

## 元数据共享
### 概述
1. 元数据共享是指数管系统把它扫描收集和管理的元数据, 共享给其他子系统使用的过程
1. 由于每一个子系统, 对元数据的管理需求不同, 对元数据的质量要求也不同, 因此元数据与每一个子系统的适用情况, 需要在系统中体现
### 应用分析
1. 根据项目情况, 系统提供选项:
    1. 每一批数据入库后, 系统自动执行元数据共享的分析和同步. 比如在数据入库后, 符合即时服务产品要求的元数据, 自动同步到即时服务产品的数据列表中; 
        符合区域遥感监测产品要求的元数据和数据实体, 将自动导入区域遥感监测产品的数据表中
    1. 部分元数据, 可能需要审批后, 方可共享给其他子系统, 比如北京二号的服务中, 国内的数据, 自动发布到国内的服务门户系统里; 国际的元数据, 自动发布
        到国际的云平台中; 部分专用的编目, 要发布到业务创新部的编目服务系统中...
### 元数据共享管理
1. 数据管理员通过元数据共享功能, 可以查看元数据的共享能力
1. 数据管理员打开元数据共享功能, 系统显示如下视图
    1. 数据视图
        1. 名称
        1. 类型
        1. xxx子系统   通过\等待审批\禁用   原因
        1. xxx子系统   通过\等待审批\禁用   原因
        1. xxx子系统   通过\等待审批\禁用   原因
        1. ...
    1. 子系统视图
        1. 子系统列表
        1. 选择每一个子系统, 显示该系统下可用的编目\待审批的编码\禁用的编目
            1. 名称
            1. 类型
            统计个数
1. 数据管理员可以对等待审批的数据, 手工审批至通过, 并将备注填入 

### 元数据共享日志
1. 数据管理员可以通过元数据共享日志功能查看共享的记录
    1. 子系统视图
        1. 子系统列表
        1. 选择每一个子系统, 显示该系统下同步过的编目
            1. 名称
            1. 类型
            1. 同步日期
            统计个数
***
# 框架设计
## 调度设计
### 调度任务
1. 任务是指需要运行的并行或定时处理的工作, 包括一系列的判断, 处理, 操作目录和数据库等等(理解即可)
1. 任务的代码, 在一个特定类中编写, 这个类要依照特定的规范, 存储在特定的目录下(开发人员了解即可)
1. 任务的启动, 停止等管理, 在数据表sch_center_mission表中
1. 每一条记录, 是一个任务, 根据scmTrigger的不同, 可以分类为:
   * db_queue: 数据库队列, 特点: 从数据库队列中抢任务执行, 直至数据库队列中无任务
   * cron: 基于cron语法的时间调度, 特点: 如果任务时间长, 期间应执行的调度, 将被"消化"掉, 仅仅在任务执行完毕后的下一次运行
   * interval: 每隔x秒\分钟\小时\天\周\月, 指定的任务, 特点: 从上次任务结束后, 再过x单位时间, 下一次任务才执行
   * date: 指定时间运行一次的任务, 特点: 在规定的日期时间启动, 只运行一次
   * mem_queue: 后续会与rabbitmq, 或者redis等内存队列对接(暂未实现)
   * other: 其他(暂未实现)
1. 调度表sch_center_mission中的scmCommand和scmStatus配合, 完成并行的控制, 目前提供如下调度控制:
   * scmCommand=start&scmStatus=1: 启动调度
   * scmCommand=stop&scmStatus=1: 停止调度
     如果需要加速或减速, 只能停止调度->修改调度配置->启动调度
   * 当所有记录!!!的scmCommand=shutdown&scmStatus=0: 调度停止, 且调度系统关闭退出
1. sch_center_mission中可以登记的任务, 其处理算法为特定类, 该类存储在imetadata\job子目录下, 该子目录下子目录是任务触发的类型, 具体参见上面对
scmTrigger的描述, 字段scmAlgorithm就负责记录具体类型子目录下的类名称(不包含.py扩展名), 如:
   * db_queue类型下有job_dm_root_parser.py
     就可以在数据表中登记: 

     |scmTrigger|scmAlgorithm|说明|
     |  ----  | ----  | ----  |
     |db_queue|job_dm_root_parser|根目录扫描调度, 处理dm2_storage表队列, dsStatus:0->1->2->0|

1. scmParams是具体任务执行的参数, 格式为Json, 根据不同的scmTrigger, 参数可以进行自定义, 多个参数, 可以结合:

     |scmTrigger|scmParams|说明|样例|
     |  ----  | ----  | ----  | ----  |
     |interval|trigger.start_date|可选, 任务调度的有效开始时间|{"trigger": {"start_date": "2020-01-01 11:11:11"}}|
     |interval|trigger.end_date|可选, 任务调度的有效结束时间|{"trigger": {"end_date": "2020-01-20 11:11:11"}}|
     |interval|trigger.seconds|可选, 但是下面的时间间隔至少有一个!, 每隔x秒执行一次|{"trigger": {"seconds": 30}}|
     |interval|trigger.minutes|可选, 每隔x分钟执行一次|{"trigger": {"minutes": 30}}|
     |interval|trigger.hours|可选, 每隔x小时执行一次|{"trigger": {"hours": 2}}|
     |interval|trigger.days|可选, 每隔x小时执行一次|{"trigger": {"days": 2}}|
     |interval|trigger.weeks|可选, 每隔x星期执行一次|{"trigger": {"weeks": 2}}|
     |db_queue|job.db_server_id|数据库队列, 引用的数据库的标识, 该标识在settings.py中定义|{"job": {"db_server_id": "2"}}|
     |db_queue|job.abnormal_job_retry_times|异常任务的重试次数, 默认为3次 *|{"job": {"abnormal_job_retry_times": 5}}|
     |db_queue|process.parallel_count|并行worker的个数|{"process": {"parallel_count": 1}}|

     注意: 
     >> *异常任务的重试处理, 必须自行在子类中解决, 参见job_dm_obj_metadata. 这里本想在基类中直接重试, 但考虑到这样重试成功率不高, 还是让
         另外一个并行来重新抢占会好一些
***
# 功能设计
## 数据管理

### 数管存储设计
#### 存储类型
1. 在线存储: 是数据存储专用的存储, 用于存储所有归档的数据, 该存储由数管系统独占可写权限, 其他系统只能具有读权限
1. 入库存储: 是数据入库专用的存储, 用于个人或其他子系统将待入库的数据临时存放在该区域, 数管系统将在合适的时机, 将该区域的数据入库并迁移到核心存储中, 完成入库
    * 入库存储, 实际也是系统实时监控的存储
    * 入库存储, 是集中式存储中, 被监控的目录, 该目录下的数据, 允许定时扫描入库, 每一次定时扫描入库, 都是一个新的入库批次
1. 混合存储: 兼顾入库和在线存储的功能
    * 混合存储中的数据, 必须通过指定目录进行入库
    * 入库后的目录, 原则上不允许再次入库

#### 应用模式
1. 离散入库模式
    1. 数据先放在存储里, 再入库, 入库后, 数据实体的位置不发生变化
    1. 直接对核心存储进行管理, 入库时, 也是直接对核心存储中的目录进行处理
    1. 一般采用混合存储类型支持
1. 集中入库模式
    1. 数据先放在入库存储中, 经过扫描\质检后, 再迁移到核心存储中
    1. 不能对核心存储进行维护, 入库时, 需要对入库存储进行处理, 由系统将数据迁移到核心存储中
    1. 一般采用入库存储和在线存储搭配支持
#### 数管流程设计
1. 首次使用系统
    1. 注册存储
        * 注册核心存储: 设置核心存储的配额
        * 注册交换存储
    1. 全面盘点
        * 系统将扫描核心存储中的所有已有数据目录和文件
        * 系统对目录和文件进行对象识别
        * 系统对质量进行检查
        * 系统将提取对象的元数据, 业务元数据, 空间, 时间, 业务标签, 可视化等各类信息
1. 新数据入库
    * 用户将待入库数据存放在交换存储中
    * 系统对交互存储目录进行实时监控, 对待入库数据进行扫描\对象识别\质检
    * 根据系统定义规则, 对待入库数据进行如下处理:
        * 全部数据自动入库: 不管数据质量如何, 全部数据入库
        * 合格数据自动入库: 仅仅数据质量符合质检要求的数据入库
        * 数据管理员对待入库的数据进行人工审批, 对审批后的数据, 按上述两种方案之一进行入库
    * 数据入库的规则: 
        * 特定类型数据, 迁移至核心存储的特定目录下, 目录名可按部分元数据的信息进行创建
    * 示例:
        * 原始数据: 可以以目录为单位, 存储在指定目录下, 新子目录名称为yyyy\mm\dd\<入库批次编号>\<入库目录名>
        * 优选成果: 可以以目录为单位, 存储在指定目录下, 新子目录名称为: yyyy\mm\dd\<入库批次编号>\<入库目录名>
        * 项目成果: 可以以目录为单位, 存储在指定目录下, 新子目录名称为: 项目名称\期别\<入库批次编号>\<入库目录名>
        * 单景正射成果: 可以以目录为单位, 存储在指定目录下, 新子目录名称为: yyyy-mm-dd\<入库批次编号>\<入库目录名>
        * 镶嵌成果: : 可以以目录为单位, 存储在指定目录下, 新子目录名称为: 行政区划编码\<入库批次编号>\<入库目录名> 
        ......
1. 定期检查
    * 系统将检查库中已有的对象, 对对象的数据(对象的文件, 对象的附属文件)存在性进行检查和核实
    
#### 数管交互式系统数据入库内容设计
##### 存储管理
1. 功能: 对dm2_storage表进行维护
1. 维护内容:
    1. dm2_storage
        1. dstid: 标识
        1. dsttitle: 标题
        1. dstunipath: 
            1. 网络存储路径
            1. 一般为//ip/共享目录名称
        1. dstwatch:
            1. 默认值: 0
        1. dstwatchperiod
            1. 默认值: 2
        1. dstscanlasttime
            1. 保持为Null
        1. dstscanstatus
            1. 保持为0
        1. dstmemo
            1. 按需存储文档
        1. dstotheroption
            1. 保留字段, 用于对存储进行特殊设置
            1. Json格式
        1. dsttype
            1. 数据存储类型
            1. 可选:
                1. core: 数管专用存储, 支持集中式入库
                1. inbound: 入库专用存储, 支持集中式入库
                1. mix: 混合存储, 数管和入库通用, 支持离散式入库
        1. dstuserid
            1. 管理员标识
        1. dstownerpath
            1. 数管系统的路径
            1. 一般linux的本地mount后的路径
            1. 如果是windows运行环境, 本字段可以不填

##### 入库前质检管理
1. 功能: 对dm2_storage_inbound表进行维护
1. 维护内容:
    1. dm2_storage_inbound
        1. dsiid
            1. 序列
            1. 自动生成
        1. dsistorageid
            1. 存储标识
        1. dsidirectory
            1. 相对路径: 不包含storage根目录部分
            1. 斜线开头, 示例: /广西影像数据
        1. dsidirectoryid
            1. 一个uuid
        1. dsibatchno
            1. 批次标识
            1. 需要有算法支持
            1. 格式: yyyy-mm-dd-xxx
            1. 一天内的批次, xxx为从001开始的自增序列
        1. dsiotheroption
            1. 保留字段, 用于对待入库数据进行特殊设置
            1. Json格式
        1. dsimemo
            1. 备注
        1. dsiuserid
            1. 操作人标识
1. 注意:
    1. 如果需要在用户选择质检后提交入库, 无需人工再次审批, 可以由UI交互界面将dsiStatus的值:
        1. 从  IB_Status_QI_Finished = 4  改为  IB_Status_IB_Wait_Audit = 8
            
##### 审批入库管理
1. 功能: 对dm2_storage_inbound表进行维护
1. 维护内容:
    1. dm2_storage_inbound
        1. dsistatus
            1. 状态
            1. 设置为: IB_Status_IB_InQueue = 5


***

##### 全面盘点
1. 首次使用系统, 将数据一次性迁移到核心存储中, 并在核心存储中, 对该批数据进行全面的扫描\识别\质检\元数据解析等工作
1. 全面盘点支持全面盘点, 或者对某目录下的数据进行盘点
1. 全面盘点的定位, 是将目前库中的数据进行全面的重构, 系统虽然采用了部分优化措施, 但从结果来说, 是对数管数据库的一次重建, 全面盘点后, 不保证
    本次盘点结果与上次盘点结果的完全一致性(比如标识等字段内容)!!!
1. 全面盘点是对核心存储的一次性处理, 不支持定时扫描等功能
1. 全面盘点将丢失原有的入库批次等信息

###### 流程设计
1. 用户在可视化界面上选择指定核心存储
1. 用户选择全面盘点
1. 用户对全面盘点的处理选项进行设置
    * 盘点的模式: 全部重新盘点\检查盘点. 前者将把已经入库的记录清空, 重新进行一次扫描入库; 后者仅仅扫描已有目录, 对变化或新增的目录或文件进行扫描更新
1. 用户在可视化界面上将能看到全面盘点的进度和最终结果

###### 存储管理
1. 全面盘点仅仅对核心存储有效 

###### 技术路线
1. 全面盘点, 实际就是对核心存储中的数据, 进行一次性, 不移动数据实体的入库
1. 全面盘点, 将对核心存储中的数据进行扫描, 识别, 元数据提取和更新等

###### 其他
1. 全面盘点应用在核心存储因硬件环境发生较大变化后, 对存储中的数据进行一次性重新处理
1. 全面盘点也应用在数据识别规则发生较大变化后, 为避免已入库数据不不符合新规则, 而重新进行识别和处理
***
##### 日常盘点
1. 日常盘点是数管系统日常运行时的常规盘点工作
1. 日常盘点仅仅对库中的对象的存在合法性进行检验, 不再进行元数据解析等复杂步骤
1. 日常盘点将出具日常盘点报告, 对盘点异常情况进行统计和警告, 但不直接改变已经入库数据的属性. 由管理员手工处理异常情况.

###### 流程设计
1. 用户在可视化界面上选择指定核心存储
1. 用户选择日常盘点
1. 用户在可视化界面上将能看到日常盘点的进度和最终结果

###### 存储管理
1. 日常盘点仅仅对核心存储有效 

###### 技术路线
1. 日常盘点, 仅对库中的对象是否存在进行检验, 核对对象所属的文件或目录是否存在, 不对目录或文件的可读性\完整性\质检结果\元数据等进行检查

###### 其他
1. 日常盘点, 是常规检查, 仅确保数据存在
***
##### 新数据入库
###### 流程设计
1. 新数据使用专用的软件工具迁移或复制到待入库的共享存储目录下, 工具中将要求用户输入本批数据的类型(也就是构建业务数据集的信息), 工具在数据迁移完毕后,
    才将业务数据集的标识文件写入目录
1. 目录定时扫描工具, 将扫描数据目录, 对有标识文件的目录进行入库. 系统也可手工启动立即扫描
1. 扫描结果和进度, 将在可视化系统模块界面上显示
1. 扫描完毕后, 可视化模块中将显示本次扫描的所有目录\对象和文件信息
    1. 目录: 显示相对目录路径
    1. 文件: 显示文件列表, 可以识别为对象的, 显示对象的图标\名称\类型
    1. 对象: 显示对象的名称\类型\大小等
        1. 如果是卫星数据, 则同时显示格式(压缩包\目录\零散文件)
        1. 显示对象重复情况, 具体为: 是否重复, 重复类型: 是与库中重复, 还是在交换存储中存在重复数据
        1. 显示对象质检概况, 包括总体完整性\元数据\业务元数据\数据...
1. 考虑了一下, 为了减轻入库算法的复杂性, 这里禁止用户选择处理模式, 改为必须全部批次一次性完整入库
    1. 如果用户禁止质检不通过的数据入库, 则需要手工移出或删除这些质检不通过的数据
    1. 如果用户对于特定类型的数据禁止入库, 则需要手工移出或删除这些类型的数据
    1. 在用户移出不入库的数据后, 将使用重新扫描, 以刷新最新的数据
1. 最后用户总会选择全部入库    
1. 暂时放弃的逻辑: 
```
1. 用户可以选择处理模式:
    1. 通过勾选, 设置特定对象不入库
    1. 设置重复数据批量勾选模式:
        1. 按照压缩包, 目录其次, 零散文件最后的优先顺序, 自动勾选, 并取消其他重复数据
        1. 质检情况: 正常的自动勾选; 不正常的, 取消勾选; 其他, 高亮显示, 等待手工勾选
1. 启动入库:
    1. 系统将用户勾选确认的数据, 进行数据迁移, 并完成入库过程
```
    
###### 存储管理
* 数据存储目录管理
    1. 新数据入库有多个子目录, 类似于windows目录管理中的图片\音乐\视频...
    1. 新数据入库的每一个子目录, 代表着一类类型, 不同类的数据, 放置在不同的目录下
    1. 新数据入库时, 系统会内置入库批次编号, 编码规则为: <YYYY>-<MM>-<DD>-<SeqNo(3)>, 样例: 2020-01-01-001
    1. 新数据的类型, 初步定义为如下几种:
        1. 卫星数据
        1. 优选卫星数据
        1. 单景正射数据
        1. DOM数据
        1. DEM数据
        1. 三调
        1. 国情
        1. ...
        1. 其他成果: 
    1. 这些目录, 在各自的dstOtherOption中配置它们是何种类型, 遵循哪种规则入库

* 用户对数据包入库的设定存储结构
    1. 用户对每一个数据目录(注意, 是根目录), 都可以设定一些特定的输入参数
    1. 这些参数, 存储在dm2_storage_InBound表中的sdiOtherOption字段中, 以Json格式存储
    1. 这个Json格式详细介绍如下:
        ```json
        {
          "root": {
            "option": {
              "check_file_locked": 0,
              "check_file_locked_comment": "0=False;-1=True. 是否在入库前, 检查所有文件是否被锁定. 注意: 如果是切片, 这个过程耗时会很长! "
            } 
          }
        }
        ```
       本特性, 暂未实现, 留作后续扩展

###### 技术路线
1. 交换存储将被设计为一个特定的storage, 在这个存储下, 每一个一级目录, 将视为一个业务数据集, 作为一个批次进行录入
1. 系统针对storage进行扫描处理, 处理的基本单元为一级子目录, 如发现一级子目录下有特定标识文件, 则表明该目录做好了数据入库的准备, 系统将开始进一步
    扫描其子目录和文件, 并开始识别数据, 发现认识的数据对象, 进行相关的质检和元数据抽取处理工作
1. 用户通过可视化系统查看进度, 并选择具体入库的数据, 选择的结果, 将保存在目录\文件\对象表的OtherOption字段中, 这个字段是json格式, 可以存储和
    容纳多个业务属性
1. 用户确认开始入库时, 系统将按如下步骤完成入库工作:
    * 重新检查库中的记录, 是否与实体相符(只检查库中的记录, 在实体目录下是否存在)
    * 将入库记录归档到专用的入库日志表中
    * 标记入库记录中的目录\文件可用性为"待确认"
    * 将待入库的数据根目录一次性移动至核心存储中
    * 更新编目记录, 挂接在核心存储的编目中(这样, 原数据的所有记录, 包括对象识别的元数据, 都将保留)
    * 将最后确认的入库记录的目录\文件可用性更新为"可用"
1. 采用上述技术方案的好处:
    1. 如果交换存储和核心存储采用同一个存储介质, 则数据入库的过程效率将极高
    1. 编目记录更新挂接, 将提高数据入库的效率, 避免二次扫描带来的时间和性能消耗

###### 入库内容
1. 目录
1. 文件
1. 识别出的对象
    1. 名称
    1. 类型
    1. 数据类型: 文件\目录\其他
    1. 标签: 对数据进行归类, 包含业务类型
    1. 实体元数据
    1. 业务元数据
    1. 时间
        * 详细时间
        * 开始时间
        * 结束时间
    1. 空间
        * 原始中心点
        * 原始四至
        * 原始外边界
        * WGS84中心点
        * WGS84四至
        * WGS84外边界
        * 投影坐标wkt
        * 投影坐标proj4
        * 投影
        * 坐标系
        * 分度
        * 分带
    1. 重复性
        * 核心存储中的, 同名对象个数:
        * 核心存储中的, 同名同大小对象个数: 
        * 本批次内, 同名对象个数:
        * 本批次内, 同名同大小对象个数:
    1. 质量
        * 质检详情
        * 质检概要
    1. 可视化
        * 快视图
        * 拇指图

### 数管与第三方系统的发布设计
#### 发布权限和规则
##### 数管部分
1. 数管的每一个对象, 维护着一个与第三方系统的关系列表
1. 这个关系使用json格式
1. json的一级key为每一个系统的名称, 举例:
    ```json
    {
        "module_datamining": {
            "audit": "system",
            "title": "数据分析挖掘",
            "result": "wait",
            "message": "模块[module_datamining.数据分析挖掘]对对象[数据集名称]的访问能力已经分析完毕!"
        },
        "module_data2service": {
            "audit": "system",
            "title": "数据服务发布",
            "result": "pass",
            "message": "模块[module_data2service.数据服务发布]对对象[数据集名称]的访问能力已经分析完毕!"
        },
        "module_distribution": {
            "audit": "system",
            "title": "数据检索分发",
            "result": "pass",
            "message": "模块[module_distribution.数据检索分发]对对象[数据集名称]的访问能力已经分析完毕!"
        },
        "module_day_photography": {
            "audit": "system",
            "title": "日新图",
            "result": "forbid",
            "message": "模块[module_day_photography.日新图]对对象[数据集名称]的访问能力已经分析完毕!"
        }
    }
   ```
   其中:
   * module1-3: 为三个子系统的名称
   * forbid: 禁止发布到该子系统
   * wait: 待审批后, 方可发布到该子系统
   * pass: 可直接发布到该子系统
1. 数管对象在刷新或更新状态时, 将对上述关系字段进行更新
1. 如果规则变化, 数管也将使用特殊机制, 刷新整个关系字段, 或者更新其中特定模块的关系
1. 数管的审批, 将在数管的可视化模块中实现, 经过审批的模块, 将会更新关系字段, 内容如下:
    ```json
    {
        "module_datamining": {
            "audit": "user",
            "title": "数据分析挖掘",
            "result": "pass", 
            "username": "管理员...", 
            "datetime": "2020-10-14",
            "message": "模块[module_datamining.数据分析挖掘]对对象[数据集名称]的访问能力已经分析完毕!"
        },
        "module_data2service": {
            "audit": "system",
            "title": "数据服务发布",
            "result": "pass",
            "message": "模块[module_data2service.数据服务发布]对对象[数据集名称]的访问能力已经分析完毕!"
        },
        "module_distribution": {
            "audit": "system",
            "title": "数据检索分发",
            "result": "pass",
            "message": "模块[module_distribution.数据检索分发]对对象[数据集名称]的访问能力已经分析完毕!"
        },
        "module_day_photography": {
            "audit": "system",
            "title": "日新图",
            "result": "forbid",
            "message": "模块[module_day_photography.日新图]对对象[数据集名称]的访问能力已经分析完毕!"
        }
    }
    ```
1. 上述json中, 每一个子系统的内容, 除了audit和result两个属性外, 可以有规则的扩充

##### 第三方系统
1. 第三方系统中, 记录和维护已经发布的数据对象的标识, 名称, 大小以及最后修改时间, 并且使用后者(名称, 大小以及最后修改时间)计算md5码作为指纹, 判断
    数据是否与上次有改变
1. 如果第三方系统的数据表, 与数管的数据表在同一个库中, 可以直接通过sql查询进行判别
1. 如果第三方系统的数据表, 与数管的数据表, 分别在两个数据库中, 可以通过调度, 逐一判断每一个对象是否有更新
1. 第三方系统在从数管的数据表中提取数据时, 必须根据关系字段中的定义, 判断自己是否有权直接使用某数据

#### 通知机制
##### 自动机制
1. 一个批次数据入库完毕, 将自动启动该批次数据的通知

##### 手动机制
###### 向所有子系统通知一遍
1. 将inbound表的dsiOtherOption(jsonb)中的notify.module=None
1. 将inbound表的dso_na_status设置为1
1. 后台系统将自动同步该批次的所有对象到全部第三方系统

###### 新增一个子系统后, 可指定批次向特定子系统通知
1. 将inbound表的dsiOtherOption(jsonb)中的notify.module=["子系统1标识", "子系统2标识"]
1. 将inbound表的dso_na_status设置为1
1. 后台系统将自动同步该批次的所有对象到指定第三方系统

#### 发布机制
##### 被动机制
1. 第三方系统应查询inbound表, 检查是否有正在入库的数据. 如果有, 则等待入库结束后, 再进行数据发布.

##### 主动机制
1. 在inbound表中, 有一个na调度(notify_app), 在每一个批次数据发布成功结束后, 将触发该调度, 在调度中, 可以主动通知第三方应用, 甚至可以进行该
    批次的编目同步等等!
1. 这样, 通知机制, 仅仅在一个批次完成后才触发!
1. 一个批次入库后, notify_app任务启动, 系统将启动每一个模块的通知机制
    1. 模块的入库将
1. 目前没有触发单个模块的

#### 说明
1. 原设计数管中, 对象的版本, 后发现该版本号也需要在第三方系统数据库或数据表中记录, 并且需要判断该记录的更新状态, 这与对象的最后修改时间这个字段的意
    义是相同的, 所以, 也可以直接使用对象的最后修改时间, 或者对象的大小以及最后修改时间联合形成的md5码作为更新指纹的比较依据, 会更稳定一些.
1. 具体可参考影像数据发布中, 对数据的获取和使用规则

#### 扩展的功能
1. 重新检查
    1. 在规则发生变化, 或者新增第三方系统后, 往往需要重新检查所有数据是否符合规则要求
    1. 可以考虑针对特定模块, 重新检查; 还是所有模块重新检查
    1. 可以考虑是针对系统检查的结果进行重新检查(人为审核通过的, 不再重新检查), 还是所有都重新检查(人为审核通过的, 也重置, 重新检查)

#### 数据库编辑
1. 在数据对象表中, 增加三个字段:
    1. dso_da_status(int): 发布规则审核-状态
    1. dso_da_proc_id(varchar): 发布规则审核-并行标识
    1. dso_da_result(jsonb): 发布规则审核-结果

#### 元数据处理
##### 基本内容
1. 元数据处理的内容:
    1. 质检
    1. 提取并解析实体元数据
    1. 提取并解析业务元数据
    1. 提取并解析时间元数据
    1. 提取并解析空间元数据
    1. 优化空间元数据
    
##### 具体描述
###### 质检
####### 质检的定义
1. 质检是一个贯穿性的处理过程
    1. 比如: 在将实体解压缩时, 实体解压失败, 需要记录到质检中
    1. 比如: 实体解压成功后, 对解压缩后的元数据, 实体数据进行检验, 也需要记录到质检中
1. 质检是一个随时会被打断的过程
    1. 如果实体解压缩失败, 则后续的元数据提取, 影像数据可读性等质检过程都会中断
1. 质检是一个有层次的过程
    1. 实体解压缩成功, 才有后续的内容
    1. 实体元数据XML文件加载成功, 后续才能对元数据有效性进行检验

####### 质检的内容
1. 整体数据质检
    1. 整体数据可用性
        1. 数据是否可以打开
    1. 整体数据规范性
        1. 数据命名规范性
1. 数据实体质检
    1. 数据实体文件完整性
    1. 数据实体文件有效性
1. 元数据质检
    1. 业务元数据
        1. 元数据完整性
        1. 元数据文件有效性
        1. 元数据项合法性
    1. 数据元数据
        1. 数据实体格式合法性
        1. 数据元数据项合法性
        
####### 质检的结果
1. 质检的结果为xml格式文件
1. 质检的结果为分层次的节点

##### 卫星数据
###### 数据结构
1. 卫星数据压缩包, 一般数据压缩包以tar.gz, rar, zip等压缩包扩展名存储
1. 卫星数据解压缩后, 目录名与卫星数据主名相同, 一个目录中, 卫星的数据都在这个子目录下
1. 多个卫星数据解压缩在一个目录下, 目录名字没有规范, 但是这些卫星数据都在这一个目录下

##### 识别模式
###### 常规目录识别
1. 如果是目录
    1. 对目录名称进行关键字识别
    1. 对目录下的文件进行进一步识别
1. 如果是文件
    1. 如果文件扩展名是常用的压缩包
    1. 如果文件主名匹配特征码
    1. 将文件识别为对象
    
###### 自定义目录识别插件
1. 在目录下, 添加特定的标识文件, 用于管理和控制目录下的数据识别
1. 标识文件: metadata.rule
1. 标识文件的格式为xml
样例:
```xml
<?xml version="1.0" encoding="UTF-8"?>
<root>
    <type>DOM</type>
    <plugins>
        <file>
            <plugin>plugins_1000_dom_10</plugin>
            <plugin>plugins_1000_dom_12</plugin>
        </file>
        <dir>
            <plugin>plugins_1000_dom_10</plugin>
            <plugin>plugins_1000_dom_12</plugin>
        </dir>
    </plugins>
</root>
```
说明:
1. root: (*) 根节点, 不可修改和缺失
1. type: (*) 当前目录的业务类型, 等同于将目录名改为type节点中的名称, 不可修改和缺失
    * 示例中为dom, 则表明该目录将按dom类型进行数据识别
    * dom类型的识别, 参见全局设置中数管plugins的配置, 此类型等于keyword
1. plugins: (可选) 也可以在此文件中直接设置目录下识别的插件
    * 需要分别在file和dir子目录下设置文件和子目录的识别
    * 识别顺序为从上到下

    **注意: 在这里设置识别的插件后, 系统将忽略全局设置中的插件!!!**

### 数据管理并行处理算法设计
#### 数管部分
##### 根目录扫描调度-job_dm_root_parser
1. 名称: job_dm_root_parser
1. 类型: db_queue
1. 应用场景:
    1. 混合存储, 被设置为立即扫描(兼容旧版本)
1. 算法:
    1. 抢占dm2_storage表中类型为混合存储, dstScanStatus=1的记录, 状态更新为2
    1. 检查dm2_storage_directory表中是否有对应的根目录, 加入到dm2_storage_directory表中, 注意设置如下状态:
        * dsd_directory_valid=1(待确认)
        * dsdScanFileStatus=1
        * scanStatus=1
    1. 将处理成功的记录, dm2_storage表dstScanStatus设置为0

##### 集中式存储定时入库调度-job_dm_ib_storage_sch_scan_monitor

1. 名称: job_dm_ib_storage_sch_scan_monitor
1. 类型: interval
1. 应用场景: 入库存储的定时入库
1. 算法:
    1. 扫描dm2_storage表中类型为入库, 允许自动扫描, 已经完成扫描的存储
        * dstwatch = -1
        * dsttype = inbound
        * dstscanstatus = 0
    1. 检查扫描的周期, 以及最后一次扫描的时间, 计算当前时间是否应该开始扫描
        1. 如果应该扫描
            1. 设置存储的状态为允许扫描: dstscanstatus=1
            1. 设置存储扫描的最后修改时间为当前时间: dstscanlasttime=now()
            1. 设置记录的最后修改时间为当前时间: dstlastmodifytime=now()
            1. 设置扫描备注为: dstscanmemo=xxx时间, 启动扫描
        1. 如果不应该扫描
            1. 设置记录的最后修改时间为当前时间: dstlastmodifytime=now()
            1. 设置扫描备注为: dstscanmemo=xxx时间, 检查扫描条件, 目前无须扫描

##### 集中式存储立即入库调度-job_dm_ib_storage_scan_monitor

1. 扫描dm2_storage表中类型为入库, 等待扫描的存储
    * dstscanstatus = 1
    * dsttype = inbound
1. 判断当前是否有入库的批次
    1. dm2_storage_inbound.dsistorageid = dm2_storage.dstid
    1. dm2_storage_inbound.dsidirectory = /
    1. dm2_storage_inbound.dsistatus <> 0
    1. dm2_storage_inbound.dsi_na_status <> 0
1. 如果有正在入库的批次
    1. 忽略本次入库
        1. 设置存储的状态为允许扫描: dstscanstatus=0
        1. 设置记录的最后修改时间为当前时间: dstlastmodifytime=now()
        1. 设置扫描备注为: dstscanmemo=xxx时间, 启动扫描, 发现正在入库, 本次定时扫描将被忽略
    1. 启动本次入库
        1. 在dm2_storage_inbound中增加一个入库批次记录
        1. 设置记录的最后修改时间为当前时间: dstlastmodifytime=now()
        1. 设置扫描备注为: dstscanmemo=xxx时间, 启动扫描, 创建入库批次, 并开始扫描
        1. 设置存储的状态为允许扫描: dstscanstatus=0

##### 目录识别调度-job_dm_path2object

1. 名称: job_dm_path2object
1. 类型: db_queue
1. 算法:
    1. 抢占dm2_storage_directory表中dsdScanStatus=1的记录, 状态更新为2
    1. 检查目录是否存在
        1. 目录不存在:
            * 标记当前目录及以下的文件(递归)的dsfFileValid=0无效(为了高效处理)
                * dsfScanStatus=0
                * dsfFileValid=0
            * 标记当前目录及以下的子目录(递归)为dsd_directory_valid=0无效(为了高效处理)
                * dsdScanStatus=0
                * dsdScanFileStatus=0
                * dsdScanDirStatus=0
                * dsd_directory_valid=0
        1. 目录存在:
            * 检查并判断指定的元数据扫描规则文件是否与数据库中的记录相等(都是空也算相等)
                * 如果和记录中的不同
                    * 删除当前目录下的所有子目录, 文件 和对象
                    * 更新记录中的规则
                    * 设置子目录扫描状态为正常
                        * dsdScanFileStatus=1
                        * dsdScanDirStatus=1
                        * dsd_directory_valid=-1
                * 如果和记录中的相同
                    * 不处理
            * 设置当前目录的dsd_directory_valid=-1有效
            * 目录当前情况下是否是对象
                * 不知道是不是对象
                    * 开始判断是何种对象
                    * 更新对象字段
                * 是, 可能是, 不是
                    * 判断目录的最后修改时间和记录中的时间是否一致
                        * 如果无更新: 不再继续
                        * 如果有更新
                            * ***更新最后修改时间到记录中!!!(这里做, 因此, 在[目录扫描文件和子目录调度]中不能做!)***
                            * 删除旧的对象记录
                    * 开始判断是何种对象
                    * 更新对象字段
                * 识别后的结果:
                    * 不知道是不是对象
                        * dsdScanFileStatus=1
                        * dsdScanDirStatus=1
                        * dsd_directory_valid=-1
                    * 是, 可能是, 不是
                        * dsdScanFileStatus=0
                        * dsdScanDirStatus=0
                        * dsd_directory_valid=-1
   1. 将处理成功的dm2_storage_directory记录
        1. dsdScanStatus=0
   
##### 目录扫描文件和子目录调度-job_dm_path_parser
1. 名称: job_dm_path_parser
1. 类型: db_queue
1. 算法:
   1. 抢占dm2_storage_directory表中dsdScanStatus=0&dsdScanFileStatus=1&dsd_directory_valid=-1(存在)的记录, 
        状态dsdScanFileStatus更新为2
   1. 将当前目录下的子目录的dsd_directory_valid改为1(待确认), 注意不是递归
   1. 将当前目录下的文件的dsfFileValid改为1(待确认), 注意不是递归
   1. 扫描目录下的文件和子目录:
        1. 黑白名单检化验
            1. 未通过
                1. 不处理, 进行下一个
            1. 通过
                1. 如果是子目录
                    1. 检查是否是根目录, 而且存储的类型是入库存储
                        1. 检查子目录下是否有待入库标识文件, 该文件存在表明该目录已经做好了入库准备
                        1. 如果标识文件不存在
                            1. 不处理, 进行下一个
                        1. 如果标识文件存在
                            1. 检查dm2_storage_directory中是否有匹配的记录
                                1. 如有对应记录
                                    1. 检查目录最后修改时间, 与匹配的记录是否相同
                                        1. 如果相同
                                            * dsdScanStatus=0
                                            * dsdScanFileStatus=0
                                            * dsd_directory_valid=-1 
                                        1. 如果不同
                                            * ***这里不能更新记录的信息, 否则在对象识别调度中就无法判断时间有效性了!!!***
                                            * dsdScanStatus=1
                                            * dsdScanFileStatus=1
                                            * dsd_directory_valid=1 (这里是1或-1都无关系, 对象识别时, 还是要判断一下) 
                                1. 如果没有对应记录
                                    1. 添加记录
                                    1. 注意如下状态:
                                       * dsdScanStatus=1
                                       * dsdScanFileStatus=1
                                       * dsd_directory_valid=-1 (这里是1或-1都无关系, 对象识别时, 还是要判断一下)
                1. 如果是文件
                    1. 检查dm2_storage_file中是否有匹配的记录
                        1. 如有对应记录
                            1. 检查文件的大小和最后修改时间, 与匹配的记录是否相同
                                1. 如果相同
                                    * dsfScanStatus=0
                                    * dsdFileValid=-1 
                                1. 如果不同
                                    * ***这里不能更新记录的信息, 否则在对象识别调度中就无法判断时间有效性了!!!***
                                    * dsdScanStatus=1
                                    * dsdFileValid=1 (这里是1或-1都无关系, 对象识别时, 还是要判断一下)
                        1. 如果没有对应记录
                            1. 添加记录
                            1. 注意如下状态:
                               * dsdScanStatus=1
                               * dsdFileValid=-1 (这里是1或-1都无关系, 对象识别时, 还是要判断一下)
   1. 将当前目录下的子目录的dsd_directory_valid=1(待确认)的, 都改为0(无效), 注意不是递归
   1. 将当前目录下的文件的dsfFileValid=1(待确认)的, 都改为0(无效), 注意不是递归
   1. 将处理成功的dm2_storage_directory记录
        1. dsdScanFileStatus=0
        1. dsdScanDirStatus=0

##### 文件识别调度-job_dm_file2object
1. 名称: job_dm_file2object
1. 类型: db_queue
1. 算法:
   1. 抢占dm2_storage_file表中dsfScanStatus=1的记录, 状态更新为2
   1. 检查文件是否存在
        1. 如果文件不存在:
            * 标记当前文件的dsfFileValid=0无效
        1. 文件存在:
            * 设置当前文件的dsfFileValid=-1有效
            * 文件当前情况下是否是对象
                * 不知道是不是对象
                    * 开始判断是何种对象
                    * 更新对象字段
                * 是, 可能是, 不是
                    * 判断文件的大小, 最后修改时间和记录中的是否一致
                        * 如果无更新: 不再继续
                        * 如果有更新
                            * ***更新最后修改时间到记录中!!!(这里做, 因此, 在[目录扫描文件和子目录调度]中不能做!)***
                            * 删除旧的对象记录
                    * 开始判断是何种对象
                    * 更新对象字段
   1. 将处理成功的dm2_storage_file记录
        1. dsfScanStatus=0

##### 对象标签处理调度-job_dm_obj_tags
###### 版本1
1. 名称: job_dm_obj_tags
1. 类型: db_queue
1. 算法:
   1. 抢占dm2_storage_object表中dsoTagsParserStatus=1的记录, 状态更新为2
   1. 根据对象类型, 解析对象的标签
        1. 业务标签
        1. 时间标签
        1. 空间标签
   1. 将处理成功的dm2_storage_object记录
        1. dsoTagsParserStatus=0

###### 版本2
1. 名称: job_dm_obj_tags
1. 类型: db_queue
1. 升级:
    1. 升级标签的标签库和适配模式
    1. 版本1
        1. 标签库
            1. 存储预定义标签的地方
            1. 目前的标签库
                1. 时间维度标签库
                1. 空间维度标签库
                1. 通用(内置)业务维度标签库
                1. 行业标签库
        1. 匹配数据信息
            1. 针对每一个数据, 定义匹配数据信息
            1. 预定义的匹配数据信息:
                1. 入库相对路径
                1. 文件主名
    1. 版本2
        1. 标签库和标签定义
            1. 存储预定义标签的地方
            1. 标签库
                1. 时间维度标签库
                1. 空间维度标签库
                1. 通用(内置)业务维度标签库
                1. 行业标签库
                1. 自定义标签库(新增)
            1. 标签字段
                1. 标签库中, 允许有多个标签匹配值
        1. 适配数据信息
            1. 针对每一个数据, 定义匹配数据信息
            1. 预定义的匹配数据信息:
                1. 入库相对路径
                1. 文件主名
                1. 入库相对路径+文件主名
                1. 自定义
            1. 匹配数据信息的分割方法
                1. 特定分隔符
        1. 扩大标签匹配算法的自定义能力
            1. 全局级别
                1. 自定义能力
                    1. 数据识别插件中定义的默认适配数据信息
                    1. settings中定义的标签库(标签库的sql, 标签字段(单个), 标签匹配字段(可多个))
                    1. 不同标签库, 使用不同的适配模式(匹配数据信息, 分隔符)
                1. 适用于:
                    1. 不同数据均采用统一的标签库
                    1. 不同数据均采用统一的适配模式
            1. 存储级别
                1. 自定义能力
                    1. 特定存储中, 可以为该存储下的数据, 自定义专用的标签库和识别插件对应的实配数据信息
                    1. 个性化的标签库(标签库的sql, 标签字段(单个), 标签匹配字段(可多个))
                    1. 不同数据, 采用不同的适配模式(匹配数据信息, 分隔符)
                1. 适用于
                    1. 行业数据存在多个规范, 比如农普数据2015年前后的数据, 遵循的行业规范不统一, 因此, 系统提供的解决方案就是设计一
                        个新存储, 在该存储的配置中, 根据新的行业规范定义业务分类体系
                1. 存储级别设置后, 优先级高宇全局级别
            1. 数据级别
                1. 自定义能力
                    1. 针对特定数据, 配置该数据的标签库和适配模式
                1. 适用于:
                    1. 未知
                1. 数据级别设置后, 优先级高宇存储级别
   
1. 算法:
    1. 抢占dm2_storage_object表中dsoTagsParserStatus=1的记录, 状态更新为2
    1. 根据对象类型, 解析对象的标签
        1. 业务标签
        1. 时间标签
        1. 空间标签
    1. 将处理成功的dm2_storage_object记录
        1. dsoTagsParserStatus=0


##### 对象详情处理调度-job_dm_obj_detail
1. 名称: job_dm_obj_detail
1. 类型: db_queue
1. 算法:
   1. 抢占dm2_storage_object表中dsoDetailParserStatus=1的记录, 状态更新为2
   1. 根据对象类型, 清理对象的详情
   1. 根据对象类型, 重新注册对象的详情
   1. 统计对象附属文件的大小汇总, 保存到对象的容量字段中
   1. 统计对象名称和大小重复的对象个数, 保存到对象重复情况统计(jsonb)字段中
   1. 将处理成功的dm2_storage_object记录
        1. dsoDetailParserStatus=0

##### 对象元数据处理调度-job_dm_obj_metadata
1. 名称: job_dm_obj_metadata
1. 类型: db_queue
1. 算法:
   1. 抢占dm2_storage_object表中dsoMetaDataParserStatus=1的记录, 状态更新为2
   1. 根据对象类型, 处理对象的元数据
        1. 创建虚拟内容对象
        1. 质检
        1. 提取并解析实体元数据
        1. 提取并解析业务元数据
        1. 提取并解析时间元数据
        1. 提取并解析空间元数据
        1. 优化空间元数据
        1. 清理虚拟内容对象
   1. 将处理成功的dm2_storage_object记录
        1. dsoMetaDataParserStatus=0

##### 数据入库质检-job_dm_inbound_qi(quality inspection 质量检验)
1. 名称: job_dm_inbound_qi
1. 类型: db_queue
1. 算法:
    1. 抢占dm2_storage_inbound表中dsiStatus=1的记录, 状态更新为2
        1. dsiStatus = 1 等待质检
        1. dsiStatus = 2 正在质检
    1. 检查dm2_storage_directory中是否有该目录
        1. 已存在
            1. 反馈该目录记录已经入库, 不能二次入库
                1. 将dm2_storage_inbound表的dsiStatus更新为21
                    1. dsiStatus = 21 质检过程出现异常
                1. 将dm2_storage_inbound表的dsiprocmemo, 记录上述信息
        1. 不存在
            1. 在dm2_storage_directory表中创建该目录记录, 目录标识使用入库中创建的uuid, 同时状态置为立即扫描
                1. dsdscanstatus = 1
                1. dsdscanfilestatus = 1
                1. dsdscandirstatus = 1
            1. 如下字段使用默认值:
                1. dm2_storage_directory.dsd_bus_status = 'online'
                1. dm2_storage_file.dsf_bus_status = 'online'
                1. dm2_storage_object.dso_bus_status = 'online'
            1. 处理完毕
                1. 将dm2_storage_inbound表的dsiStatus更新为开始质检
                    1. dsiStatus = 3 质检开始
                1. 将dm2_storage_inbound表的dsiprocmemo, 记录上述信息
##### 数据入库质检监控-job_dm_inbound_qi_monitor
1. 名称: job_dm_inbound_qi_monitor
1. 类型: interval(30秒)
1. 算法:
    1. 搜索dm2_storage_inbound表中dsiStatus=3的记录
        1. 检查入库存储和指定目录下的所有目录dm2_storage_directory
            1. 识别完毕
                1. dsdScanStatus=0
            1. 扫描完毕
                1. dsdScanFileStatus=0
                1. dsdScanDirStatus=0
        1. 检查入库存储和指定目录下的文件
            1. 识别完毕
                1. dsdScanStatus=0
        1. 检查入库存储和指定目录下的所有对象
            1. 元数据处理完毕
                1. dsometadataparsestatus = 0
            1. 业务分类处理完毕
                1. dsotagsparsestatus = 0
            1. 附属文件处理完毕     
                1. dsodetailparsestatus = 0   
    1. 如果所有都处理完毕
        1. 将处理成功的dm2_storage_inbound记录状态标记为质检结束
            1. dsiStatus=4 质检完毕
        1. 根据项目情况, 如用户要求质检完全通过的数据, 应能自动入库, 则这里需要有判断标准, 如质检无误, 可将
            状态修改为提交入库
                1. dsiStatus=5 提交入库
        
##### 数据入库调度-job_dm_inbound
1. 名称: job_dm_inbound
1. 类型: db_queue
1. 算法:
    1. 抢占dm2_storage_inbound表中dsiStatus=5的记录, 状态更新为6
        1. dsiStatus=5 提交入库
        1. dsiStatus=6 正在入库
    1. 重新检查
        1. 检查所有的目录\子目录是否都存在
        1. 检查所有的文件是否都存在
        1. 如果有任何一个目录或文件不存在, 或者最后修改时间\大小发生改变, 都提示, 并停止入库
    1. 判断dsiStorage对应的存储的类型
        1. 是[入库存储], 表明该数据必须要迁移到核心存储中
            1. 预处理:
                1. 计算目录所需要的空间
                    1. 空间大小 = 全部空间 - 不入库的对象的空间
                1. 检查目录下是否有metadata.21at文件
                    1. 如果文件不存在:
                        * 标记当前目录的数据集类型为other
                    1. 如果文件存在:
                        * 读取文件中的数据集类型
                1. 从全局配置中读取特定类型的配置, 如果不存在, 则读取默认的入库配置
                1. 根据入库配置, 计算应该入库的目标存储
                    1. 如果是指定目标存储模式
                        1. 如果指定存储不存在
                            1. 反馈并记录入库备注
                            1. !!!
                        1. 如果指定存储存在
                            1. 使用该存储
                    1. 如果自动匹配存储模式
                        1. 检索存储中, 可用存储为-1或者可用存储大于目录入库所需空间的那个
                        1. 默认使用第一个
                        1. 如果存储不存在
                            1. 表明存储不足, 记录入库备注并结束
                            1. !!!
                        1. 如果存储存在, 则使用该存储
                        
                1. 按入库配置, 计算入库后的目标目录
                
                1. 检查待入库数据目录, 确定所有文件都可以移动
                    1. 如果有某一个文件无法移动, 则将该文件名称记入入库备注, 并结束
                    1. !!!
            1. 实体数据迁移        
                1. 在指定存储下, 创建入库目标目录
                1. 将待入库数据移动至入库目标目录
                    1. 如果有文件移动异常, 则将所有已迁移的文件迁回
                    1. 将移动异常的文件名称, 记入入库备注中, 并结束
                    1. !!!
            1. 编目更新
                1. 根据目标目录, 从dm2_storage_directory表中搜索其id
                    1. 如果目标目录不存在, 则根据规则, 自动创建(这里可以折中, 直接挂接在根目录下)
                    1. 理论上, 目标目录一定可以创建成功, 并返回
                    1. 如果过程出现异常, 则将异常情况记入入库备注中, 并结束
                    1. !!!
                1. 将已入库目录的记录, 批量更新至目标存储和目录下
                    1. dm2_storage_directory
                        1. 将源存储和目录下的所有记录的目录和相对目录, 批量更新至目标目录下
                        1. 将源存储, 更改为目标存储
                        1. 将源根目录的父目录标识, 改为新计算出的目标目录标识(这里可以折中, 可以直接改为存储标识, 这就表明直接挂接在存储的根目录下)
                    1. dm2_storage_file
                        1. 重算文件的相对文件名字段: dsffilerelationname
                    1. dm2_storage_obj_detail
                        1. 重算附属文件的相对文件名字段: dodfilename
                1. 将对应的directory\file\object表的业务状态改为[online](原默认为: inbound)
                    1. dm2_storage_directory.dsd_bus_status = 'online'
                    1. dm2_storage_file.dsf_bus_status = 'online'
                    1. dm2_storage_object.dso_bus_status = 'online'
        1. 如果是[混合存储], 表明该数据不需要迁移, 只需要把状态修改即可
            1. 将对应的directory\file\object表的业务状态改为[online](原默认为: inbound)
                1. dm2_storage_directory.dsd_bus_status = 'online'
                1. dm2_storage_file.dsf_bus_status = 'online'
                1. dm2_storage_object.dso_bus_status = 'online'
    1. 异常
        1. 将处理成功的dm2_storage_inbound记录状态改为异常
            1. dsiStatus=61 入库过程出现异常
        1. 修改重试
            1. 将处理成功的dm2_storage_inbound记录状态改为等待入库
                1. dsiStatus=5 等待入库
    1. 最后
        1. 将处理成功的dm2_storage_inbound记录状态改为成功入库
            1. dsiStatus=0  成功入库
            
##### 数据入库后通知第三方应用调度-job_dm_inbound_notify
1. 名称: job_dm_inbound_notify
1. 类型: db_queue
1. 算法:
    1. 抢占dm2_storage_inbound表中已经入库成功的, 等待通知的待入库批次
        1. dsiStatus=0 已经入库成功
        1. dsi_na_status=1 等待通知 -> 2 正在处理通知
    1. 从dm2_storage_inbound表的dsiotheroption中加载入库通知的特殊要求
        1. 获取本次通知的子系统列表
            1. 可以通过此特性, 针对指定子系统进行通知
        1. 如果特殊要求为空
            1. 则通知所有的子系统
    1. 获取本批次的所有待通知对象列表, 分别处理
        1. 循环所有子系统通知对象:
            1. 判断当前的对象是否允许通知该子系统
            1. 如果当前的对象对该子系统的通知状态为Pass或Wait
                1. 判断dm2_storage_obj_na表中该对象通知的记录是否已经存在
                    1. 如果不存在
                        1. 在dm2_storage_obj_na表中注册该记录
                    1. 判断dm2_storage_obj_na表中该对象是否正在通知给子系统
                        1. 如果正在通知
                            下次通知
                        1. 如果已经通知完毕
                            1. 更新dm2_storage_obj_na表该记录的状态为重新通知
    1. 标识通知成功结束, 更新dm2_storage_inbound表的通知状态:
        1. dsi_na_status=2 -> 9 完成通知, 等待确认
    1. 过程出现异常:
        1. dsi_na_status=2 -> 3 通知过程出现错误
        1. dsi_na_proc_memo 错误详细信息
##### 数据入库通知进度监控-job_dm_inbound_notify_monitor
1. 名称: job_dm_inbound_notify_monitor
1. 类型: interval(30秒)
1. 算法:
    1. 搜索dm2_storage_inbound表中dsi_na_status=9的记录
        1. 将处理成功的dm2_storage_obj_na
            1. dson_notify_status=0 通知完毕
        1. 标识通知成功结束, 更新dm2_storage_inbound表的通知状态:
            1. dsi_na_status=9 -> 0 成功通知
        1. 过程出现异常:
            1. dsi_na_status=9 -> 3 通知过程出现错误
            1. dsi_na_proc_memo 错误详细信息
                
***
## 数据发布
### 场景
1. 检索分发系统中, 对系统进行全分辨率浏览
    1. 用户入库数据, 在扫描后, 识别为对象, 并对对象的可分发能力进行质检
    1. 通过质检的数据, 系统将根据质检结果, 对数据的应用能力进行判别, 不同的对象, 对第三方应用的支撑能力不同.
    1. 在服务发布子系统中正常发布的服务, 将与对象标识关联
    1. 在数据检索分发子系统中的对象编目, 也与对象标识关联
    1. 数据检索分发子系统中的编目, 将通过服务发布子系统提供的视图或其他接口, 获取对象编目发布的服务, 并加载展示
1. 日新图服务
    1. 用户入库的单景正射影像, 在扫描入库和质检后(后统称: 入库), 将合格的数据直接提交给服务发布子系统
    1. 服务发布子系统将单景正射数据, 发布为日新图服务
    1. 日新图服务有自己的专题展示\数据库结构\服务体系
1. 用户入库的数据, 可发布为服务, 支持区域遥感监测专题
    1. 每一期影像和矢量成对入库, 或者是一类数据集(注意: 神华项目的按管理公司查看数据是一个特例, 不属于本范畴)
    1. 质检通过的数据集, 可以在服务发布子系统中发布, 为区域遥感监测专题服务
    1. 影像服务
        1. 用户的影像数据, 由服务发布子系统发布为每一期一个影像服务
    1. 矢量服务
        1. 用户的矢量数据, 由服务发布子系统转储至区域遥感监测专题数据表中
        1. 区域遥感监测在系统设计时, 已经将专题数据表发布为服务, 因此, 矢量的ogc服务暂时由区域遥感监测自行维护
1. 用户入库的数据, 可发布为服务, 支持展示应用
    1. 在没有即时服务产品的功能时, 用户入库的数据, 全部(大部分)都是要发布的服务, 类似于农普或云南测绘的动态监测项目
    1. 用户数据(影像或矢量)入库后, 将合格的数据直接提交服务发布子系统
    1. 服务发布子系统将影像或矢量发布为指定服务
1. 用户入库的数据, 可发布为服务, 支持第三方业务应用
    1. 在没有即时服务产品的功能时, 用户入库的数据, 全部(大部分)都是要发布的服务, 类似于农普或云南测绘的动态监测项目
    1. 用户数据(影像或矢量)入库后, 将合格的数据直接提交服务发布子系统
    1. 用户设定服务发布的参数
        1. 支撑访问量
        1. ...
    1. 服务发布子系统将影像或矢量发布为指定服务
    1. 管理员在权限管理系统中配置服务的访问权限

### 需求分析
1. 服务发布系统是为了支持其他系统对影像\矢量数据的浏览\特效
    1. 检索分发: 
        1. 一个影像, 发布为一个服务
        1. 一个影像数据集, 发布为一个服务
        1. 一个矢量, 发布为一个服务
        1. 一个矢量数据集, 发布为一个服务
    1. 日新图:
        1. 多个影像(单景正射), 发布为一个服务
        1. 可以按"日"进行影像覆盖的查询\展示\统计
    1. 其他:
        1. 多个影像\矢量, 发布为一个服务
        1. 可以对服务的图层进行维护
        1. 可以对服务图层中数据的顺序进行批量维护(比如: 按时间优先排序)或单个维护(比如: 指定移动一个数据置顶)
    注意: 上述所述的发布为一个服务, 是从应用的视角看; 技术上可能是多个Service.
1. 服务发布系统对其他系统的支撑, 需要按权限进行
1. 服务发布系统对其他系统的支撑应用情况, 服务发布系统要做最基础的统计
1. 服务发布系统应能够对服务进行基本的管理
    1. 启动服务
    1. 停止服务
    1. 暂停服务
    1. 卸载服务
    1. 加载服务

### 设计
#### 总体设计
1. 服务发布系统是一个后台+中台, 也就意味着:
    1. 服务发布系统具备ogc服务能力
    1. 服务发布系统, 同时对内部的图层管理维护, 提供操作api
    1. 服务发布系统, 对服务的访问情况, 提供统计api
1. 服务发布系统内部需要维护服务列表
1. 服务发布系统需要屏蔽技术和性能门槛, 对外只提供服务

#### 进度设计
1. 第一阶段: 完成同类坐标投影数据, 自动发布到一个OGCService中(已完成)
1. 第二阶段: 完成不同投影坐标数据, 自动发布到一个OGCService中(目前的状态)
1. 第三阶段: 完成不同投影坐标数据, 自动发布到OGCService集群或云中

#### 权限设计
1. 服务发布系统的权限采用token+权限, 通过token对外提供访问控制
1. token的权限关联:
    1. 时间控制
    1. 空间控制
    1. 服务
    1. 图层
    1. 层级(切片访问层级)
    1. 比例尺(影像放大级别)
1. 第三方系统将token与用户\角色\应用关联

#### 统计设计
1. 服务发布系统提供基于token的数据统计
1. token的数据统计:
    1. 访问时长
    1. 访问瓦片数
    
#### 性能设计
1. 服务发布系统内部采用GISServer集成和集群设计
1. GISServer:
    1. MapServer
        1. 负责影像展示服务
        1. 负责超大矢量小比例尺渲染服务
    1. GEOServer
        1. 负责超大矢量的大比例尺渲染服务
        1. 负责中小矢量的渲染服务
1. 对外提供服务的ogcService, 在服务发布系统内部可能为集群或发布为多份
1. 允许服务发布系统通过预切片或实时切片提高服务能力, 但信息不得对外提供反馈

#### 调度设计

##### 服务存储检查配置

1. 名称: job_d2s_storage_monitor
1. 类型: interval
1. 算法:
    1. 获取dm2_storage表中核心存储和混合存储记录
        1. 获取存储标识和存储的最后更新时间
        1. 获取dp_gis_server中的所有GIS服务器
            1. 根据存储标识和存储的最后更新时间, 检查该存储是否在dp_gis_storage中成功登记
            1. 如果未登记
                1. 在dp_gis_storage中登记, 并将路径mount成功
                1. 更新状态
            1. 如果已经登记
                1. 如果存储的最后更新时间, 和登记的最后时间相同
                    1. 不处理, 进行下一个
                1. 如果存储的最后更新时间, 和登记的最后时间不同
                    1. 取消mount原路径
                    1. 按新路径, 用户名和密码, 重新mount新路径
                    1. 更新状态

##### 服务发布调度

1. 名称: job_d2s_service_deploy
1. 类型: db_queue
1. 算法:
    1. 抢占dp_v_qfg表中dpStatus=5的记录, 状态更新为6
    1. 获取dp_v_qfg_layer表中, 该服务下的所有图层
        1. 获取dp_v_qfg_layer_file中的dpdf_group_id(记得要distinct)
            1. 获取dp_v_qfg_layer_file中dpdf_group_id下的每一个file
                1. 根据dpProcessType内容, 处理新增\更新\删除
                1. 将文件信息, 写入到mapfile文件中
    1. 发布成功后:
        1. 将dp_v_qfg_layer_file中所有dpdf_processtype=delete的记录删除
        1. 将dp_v_qfg_layer_file中的记录dpdf_object_fp_lastdeploy=dpdf_object_fp
        1. 将dp_v_qfg_layer中所有dpprocesstype=delete的记录删除
        1. 将dp_v_qfg记录, 更新状态为0
            1. dpStatus=0
    1. 如果发布失败:
        1. 将dp_v_qfg记录, 更新状态为61
            1. dpStatus=61
    
##### 服务更新调度
###### 服务状态更新(人机交互)
1. 业务交互系统处理(注意顺序不能错!!!):
    1. 将dp_v_qfg_layer表中, 该服务下的所有图层的状态dpstatus, 批量更新为1(启动服务检查更新的调度)
    1. 将dp_v_qfg表中dpStatus改为2
    
###### 服务图层数据更新-job_d2s_service_layer_update
1. 名称: job_d2s_service_layer_update
1. 类型: db_queue
1. 流程:
    1. 抢占dp_v_qfg_layer表中待处理的记录:
        1. dp_v_qfg.dpStatus=2
        1. dp_v_qfg_layer.dpStatus=1
        将符合上述条件的记录, 状态更新为2
        1. dp_v_qfg_layer.dpStatus=2
    1. 读取dp_v_qfg_layer表中的dpLayer_Object属性
        1. 将dp_v_qfg_layer_file表中, 所有Layer下的记录, 状态改为删除
            1. dpdf_processType=delete
        1. 根据dpLayer_Object属性, 获取所有符合要求的对象列表, 逐一处理:
            1. 检查dp_v_qfg_layer_file中是否有该object
                1. 如果存在
                    1. 更新dp_v_qfg_layer_file中的object信息
                        1. dpdf_object_id
                            1. dpdf_object_fullname
                            1. dpdf_object_title
                            1. dpdf_object_size
                            1. dpdf_object_date
                            1. dpdf_object_fp
                    1. 对比当前对象的指纹, 和dpdf_object_fp_lastdeploy中的是否相同
                        1. 相同
                            1. dpdf_processType=same
                        1. 不同
                            1. dpdf_processType=update
                1. 不存在
                    1. 在dp_v_qfg_layer_file中增加object信息
                        1. dpdf_layer_id=dp_v_qfg_layer.dpid
                        1. dpdf_group_id=dpdf_layer_id
                        1. dpdf_object_fullname
                        1. dpdf_object_title
                        1. dpdf_object_size
                        1. dpdf_object_date
                        1. dpdf_object_fp
                        1. dpdf_processType=new
        1. 删除dp_v_qfg_layer_file表中, 所有Layer下的记录, dpdf_processType=delete的记录(不删除, 改为由服务系统清理缓存后删除)
        1. 根据dp_v_qfg_layer_file表中对象的投影坐标信息, 重新计算dp_v_qfg_layer_file.dpdf_group_id字段, 该字段记录着dp_v_qfg_layer
            中应该发布的物理层
    1. 检查当前layer下, dp_v_qfg_layer_file的记录数
        1. 如果为0, 则表示当前图层下没有可发布的文件
            1. 删除dp_v_qfg_layer记录
        1. 将处理成功的dp_v_qfg_layer记录, 更新状态为0
            1. dpStatus=0
    1. 如果期间出现异常, 则将dp_v_qfg_layer记录, 更新状态为21
        1. dpStatus=21
        1. dpProcessResult=错误信息
        1. 重试机制: 
            1. 将dp_v_qfg_layer记录, 更新状态为1
                1. dpStatus=1

###### 服务状态监控-job_d2s_service_update_monitor
1. 名称: job_d2s_service_update_monitor
1. 类型: interval
1. 定时: 每10-30秒处理一次
1. 设计:
    1. 获取dp_v_qfg表中dpStatus=2的服务
    1. 检查该服务的所有layer的dpStatus是否全部为0
        1. 如果全部为0, 则将dp_v_qfg表中dpStatus改为4(后将在全局调度中设置该默认值, 改为5, 就直接自动触发服务发布动作)
        1. 如果有状态为1, 2的记录, 则表明还有正在处理的, 继续等待下一次扫描
        1. 如果没有状态为1\2的, 但是不是全部为0, 则表明处理完毕, 但有处理错误的图层, 此时将dp_v_qfg表中dpStatus改为11
    1. 如果期间出现异常, 则将dp_v_qfg记录, 更新状态为21
        1. dpStatus=21
        1. dpProcessResult=错误信息
        1. 重试机制: 
            1. 将dp_v_qfg记录, 更新状态为2
                1. dpStatus=2

###### 服务批量创建-job_d2s_service_creator
1. 名称: job_d2s_service_creator
1. 类型: db_queue
1. 算法:
    1. 获取dp_v_qfg_schema表中等待更新的模板:
        1. dpstatus = 1
        1. 对应的dp_v_qfg表中dpStatus = 0, 表明与此模板相关的服务, 都已经发布结束, 此时方可更新服务列表
        将符合要求的模板, 状态改为正在处理:
        1. dpstatus = 2
    1. 根据dpbatchdeploy属性, 进行批量服务创建
        1. 注意: dpbatchdeploy将改为jsonb格式!!!
        1. 如果对应的dp_v_qfg.dpname已经存在, 则忽略!!!
            1. 这表明, 如果模板的配置更新了, 需要删除已经发布的服务重建!!!
        1. 新建服务, 此时服务的状态为0
            1. dp_v_qfg.dpStatus = 0
            1. 根据模板, 在dp_v_qfg_layer表中创建服务的每一个层, 状态为待处理:
                1. dp_v_qfg_layer.dpStatus = 1
                1. 由于layer所属的dp_v_qfg的状态为0, 此时layer的更新不会启动, 见job_d2s_service_layer_update
        1. 启动服务数据更新
            1. 将dp_v_qfg表中dpStatus改为2
                1. dp_v_qfg.dpStatus = 2


***
## 数据分析
### 场景
1. 用户入库的数据, 可通过自动化分析, 分析结果入库或发布为ogc服务

***
# 数据库设计

## dm2_storage_inbound

### 字段
1. dsiid
    * 类型: 字符串
    * 意义: 标识
1. dsistorageid
    * 类型: 字符串
    * 意义: 待入库数据的存储标识
1. dsidirectory
    * 类型: 字符串
    * 意义: 待入库数据的目录
    * 注意:
        * 直接对存储目录进行定期扫描时, 该值为空(非null!!!)
        * 对存储下特定目录进行扫描时, 该值为/开头的一个子目录, 如忘记该/, 系统会自动补齐该/
1. dsibatchno
    * 类型: 字符串
    * 意义: 待入库数据的批次编号
    * 注意:
        * 可视化界面无需维护该值, 保持为null即可, 系统会自动创建该批次信息
        * 如交互界面对该值进行特殊处理, 则系统会使用该值作为批次编号
1. dsiaddtime
    * 类型: 日期时间
    * 意义: 记录创建的日期时间
1. dsistatus
    * 类型: 整数
    * 意义: 质检入库的状态
    * 内容:
        * 0=入库完毕
        * 1=等待质检
        * 2=质检任务已启动
        * 21=质检任务处理过程出现异常
        * 3=质检数据入库中
        * 4=质检完毕
        * 5=等待入库
        * 6=入库中
        * 61=入库过程中出现异常
        * 8=等待审批
1. dsiproctime
    * 类型: 日期时间
    * 意义: 入库最后结束时间
1. dsiprocid
    * 类型: 字符串
    * 意义: 并行处理专用字段, 无需维护
1. dsiprocmemo
    * 类型: 大文本
    * 意义: 处理结果详情
1. dsimemo
    * 类型: 大文本
    * 意义: 入库记录备注
1. dsi_na_status
    * 类型: 整数
    * 意义: 质检入库的状态
    * 内容:
        * 0=子系统通知完毕
        * 1=等待通知子系统
        * 2=正在通知子系统
        * 3=通知过程出现错误或异常
        * 9=等待确认
1. dsi_na_proc_id
    * 类型: 字符串
    * 意义: 并行处理专用字段, 无需维护
1. dsi_na_proc_memo
    * 类型: 大文本
    * 意义: 子系统通知结果详情
1. dsidirectoryid
    * 类型: 字符串
    * 意义: 目录的标识, 为全局唯一ID
1. dsiuserid
    * 类型: 字符串
    * 意义: 用户标识, 由业务系统自行掌握
1. dsitargetstorageid
    * 类型: 字符串
    * 意义: 入库后的数据, 所属的存储标识
    * 注意:
        * 离散式存储管理模式下, 该值与待入库存储dsistorageid相同
        * 集中式存储管理模式下, 该值由系统自行决定, 保持为null即可
1. dsiOtherOption
    * 类型: jsonb
    * 意义: 入库的特殊处理
    * 示例:
        ```json
        {
            "control": {
                "switch": {
                    "check_file_locked": 0,
                    "check_file_locked_comment": "0=False;-1=True. 是否在入库前, 检查所有文件是否被锁定. 注意: 如果是切片, 这个过程耗时会很长! "
                } 
            },
            "notify": {
                "module_comment": "module属性如果设置内容, 类型为字符串数组, 表明该批次仅仅通知数组中指定的模块标识!!! 如果不设置, 则应将module设置为null!!!",
                "module": null,
                "module.other": ["module_distribution"]
            },
            "property": {
                "project": "天津测绘局数据管理项目",
                "period": "第一期",
                "year": "2020"
            }
        }         
        ```
    * 说明: 
        * control
            * 控制入库流程的配置选项
            * 内容:
                * switch
                    * 开关选项, 下面的内容, 大部分由开关组成
                    * 内容:
                        * check_file_locked: 0=False;-1=True. 是否在入库前, 检查所有文件是否被锁定. 注意: 如果是切片, 这个过程耗时会很长! 
        * notify
            * 本批次的数据, 在通知子系统时, 可以设置具体通知的子系统名称
            * 默认设置为null, 表明本批次数据将通知所有子系统
            * 可以设置module为具体数组, 控制系统仅仅通知特定的几个子系统. 本设置主要为了在第一次通知失败时, 通过修正质检选项, 重新通知子系统时使用
        * property
            * 本批次数据的属性
            * 部分项目将在入库时, 为该批次数据, 指定特定的属性, 如所属项目等
            * 可以将项目中的该类特殊属性存储在这里, 并在同步算法中, 通过入库标识, 将directory\file\object信息和property关联在一起

***
## dm2_storage
### 简述
存储
### 字段
1. dstUniPath
    1. 类型: varchar
    1. 意义: 全局路径
        * 一般使用NAS等外置存储时, 该值为\\xxx.xxx.xxx.xxx\ShareStorage
        * 第三方应用, 使用该路径, 结合对象的存储目录, 计算出实体数据存储的目录
1. dstOwnerPath
    1. 类型: varchar
    1. 意义: 私有路径
        * 如果数管系统部署在linux下, 则该值为\\xxx.xxx.xxx.xxx\ShareStorage映射到操作系统的路径
        * 如果数管系统部署在windows下, 则该值与dstUniPath值相同, 或保持为null
1. dstOtherOption
    1. 类型: JsonB
    1. 示例:
    ```json
    {
        "inbound": {
            "filter" :{
                "directory": {
                    "white_list" : "*",
                    "black_list": "" 
                },
                "file": {
                    "white_list" : "*.*",
                    "black_list": "*.abc" 
                }
            }
        },
        "mount": {
            "username": "username",
            "password": "password"
        }
    }
    ```
    1. 说明:
        * inbound: 入库的配置选项
            * 过滤规则:
                * directory: 目录过滤规则, 分为白名单和黑名单
                * file: 文件过滤规则, 分为白名单和黑名单
        * mount: linux下路径mount的规则, 分为用户名和密码
1. dsttype
    1. 类型: 字符型
    1. 说明:
        * core: 核心存储, 仅仅存储数据
        * mix: 混合存储, 入库和存储的混合类型
        * inbound: 仅仅用于临时入库的存储, 可以支持立即扫描和定时扫描
1. dstwatch
    1. 类型: int
    1. 示例: -1=True;0=False
1. dstWatchOption
    1. 类型: jsonb
    1. 示例:
    ```json
    {
        "period": "minute/hour/day/month/year",
        "minute": 5,
        "hour": 5,
        "day": 5,
        "month": 5,
        "year": 5
    }
    ```
   说明:
    * period: 时间间隔
    * minute/hour/day/month/year: 每隔n分钟/小时/天/月/年
1. dstscanstatus
    1. 类型: int
    1. 说明:
        * 0=扫描完毕
        * 1=等待扫描
        * 2=正在扫描
        * 3=扫描过程出现错误
    1. 注意: 当dsttype=core, 上述值无效!!!
1. dstscanmemo
    1. 类型: 文本
    1. 说明: 最后一次扫描的结果日志
1. dstscanlasttime
    1. 类型: 日期时间
    1. 最后一次扫描时间, 由系统控制, 个人无需维护, 设置为null即可
1. dstprocessid
    1. 类型: 字符型
    1. 说明: 系统并行处理使用的字段, 个人无需维护.
1. dstaddtime
    1. 类型: 日期时间
    1. 说明: 记录添加的时间
1. dstlastmodifytime
    1. 类型: 日期时间
    1. 说明: 记录最后一次修改的时间
1. dst_volumn_max
    1. 类型: 大整数
    1. 说明: 当前存储可入库数据的最大容量, 单位:bit
1. dst_volumn_warn
    1. 类型: 大整数
    1. 说明: 当前存储可入库数据的警告容量, 单位:bit
1. dst_volumn_now
    1. 类型: 大整数
    1. 说明: 当前存储已入库数据的容量, 单位:bit
    1. 暂未启用
1. dstuserid
    1. 类型: 字符型
    1. 说明: 存储维护的人员, 用于业务管理

## dp_v_qfg
### 简述
### 字段
1. dpid
    * 类型: varchar
    * 意义: 标识
1. dpStatus
    * 类型: int
    * 意义: 状态
        * 0: 成功完成发布
        * 1: 等待发布
        * 2: 发布中-正在处理
        * ...
        * 5: 发布中-等待发布为ogc服务
        * 6: 发布中-正在筹备ogc服务发布前的预备工作
        * 61: 发布中-筹备ogc服务发布前的预备工作失败; 重试请更改为5
        * 7: 发布中-已经提交给ogc服务器, 等待处理完成
        * 81: 发布中-已经提交给ogc服务器, 但ogc服务器发布失败
        * ...
1. dpProcessID
    * 类型: varchar
    * 意义: 并行处理标识

## dp_v_qfg_layer
### 简述
### 字段
1. dpid
    * 类型: varchar
    * 意义: 标识
1. dplayer_object
    * 类型: jsonb
    * 意义: 图层所需要的数据对象类型
    * 示例:
        ```json
        {
            "id": ["plugins_3000_gdb"]
            , "name": ["dom", "dem"]
            , "type": ["vector"]
            , "data_type": ["file"]
            , "group": ["industry_data"]
            , "tag": ["aa", "bb"]
        }
        ```
        **注意: 大小写不敏感**
        **上述条件对应为object_def表中的dsodid\dsodname\dsodtype\dsodgroupname**
        
## dp_v_qfg_layer_file


***
# 依赖第三方部件
## tika
### 简介:
1. apache tika
The Apache Tika™ toolkit detects and extracts metadata and text from over a thousand different file types 
(such as PPT, XLS, and PDF). All of these file types can be parsed through a single interface, 
making Tika useful for search engine indexing, content analysis, translation, and much more. 

### 支持数据格式:
[完整数据格式列表](https://tika.apache.org/1.24/formats.html#Full_list_of_Supported_Formats)

### 安装:
1. 安装java\jdk
1. 安装tika

### 启动:
#### macos
1. 客户端启动
    ```
    在/usr/local/bin下运行tika
    将启动tika的java客户端
    ```
   如果需要直接使用客户端的jar, 则需要在如下目录中查找
   /usr/local/Cellar/tika/1.24.1_1/libexec
   有两个jar包:
   * tika-app-1.24.1.jar: 客户端应用程序
   * tika-server-1.24.1.jar: 服务器应用程序
1. 服务器启动
    ```
    在/usr/local/bin下运行tika-rest-server
    将启动tika的rest服务器
    ```

# 主要设计调整
## 2020-12-22
1. 数据附属文件, 从以前的相对数据主文件的相对路径, 改为相对存储的相对路径, 需要同步调整如下内容:
    1. 集中迁移式入库功能中, 需要在迁移后, 同步更新数据附属文件的路径!!!
1. 数据附属文件中, 支持存储一个目录作为其附属文件记录, 同时统计出该目录下的文件个数\子目录个数和文件总容量合计